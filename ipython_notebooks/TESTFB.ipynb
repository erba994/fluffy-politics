{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "creator": "admin",
    "createdOn": 1634026539876,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Populating the interactive namespace from numpy and matplotlib\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd\nimport fbcrawl"
      ],
      "outputs": []
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!scrapy"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Scrapy 2.5.1 - no active project\r\n\r\nUsage:\r\n  scrapy \u003ccommand\u003e [options] [args]\r\n\r\nAvailable commands:\r\n  bench         Run quick benchmark test\r\n  commands      \r\n  fetch         Fetch a URL using the Scrapy downloader\r\n  genspider     Generate new spider using pre-defined templates\r\n  runspider     Run a self-contained spider (without creating a project)\r\n  settings      Get settings values\r\n  shell         Interactive scraping console\r\n  startproject  Create new project\r\n  version       Print Scrapy version\r\n  view          Open URL in browser, as seen by Scrapy\r\n\r\n  [ more ]      More commands available when run from project directory\r\n\r\nUse \"scrapy \u003ccommand\u003e -h\" to see more info about a command\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!scrapy crawl events -a email\u003d\"lorenzotosi1206@gmail.com\" -a password\u003d\"Cycling1294\" -a lang\u003d\"en\" -a page\u003d\"http://mbasic.facebook.com/groups/675823305849812/\" -o \"pagnagna.csv\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Scrapy 2.5.1 - no active project\r\n\r\nUnknown command: crawl\r\n\r\nUse \"scrapy\" to see available commands\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true
      },
      "source": [
        "from twisted.internet import reactor\nimport scrapy\nfrom scrapy.crawler import CrawlerRunner\nfrom scrapy.utils.log import configure_logging\n\nconfigure_logging({\u0027LOG_FORMAT\u0027: \u0027%(levelname)s: %(message)s\u0027})\nrunner \u003d CrawlerRunner()\n\nd \u003d runner.crawl(MySpider)\nd.addBoth(lambda _: reactor.stop())\nreactor.run() # the script will block here until the crawling is finished\nSee also"
      ]
    }
  ]
}